# -*- coding: utf-8 -*-
"""Detecção de emoção - Arquitetura 1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DpgZKs6u9_4mP9PXRax82DzLrZQ-VWep

## Etapa 1 - Importando as bibliotecas
"""

import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow
import zipfile

cv2.__version__

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow
tensorflow.__version__

"""## Etapa 2 - Conectando com o Drive e acessando os arquivos"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

#Extraindo todos os arquivos do Material.zip
path = "/content/drive/My Drive/Material.zip"
zip_object = zipfile.ZipFile(file=path, mode="r")
zip_object.extractall("./")

#Extraindo fer2013.zip para obter uma base de imagens que serão utilizadas no treinamento do modelo
base_imgs = 'Material/fer2013.zip'
zip_object = zipfile.ZipFile(file=base_imgs, mode='r')
zip_object.extractall('./')
zip_object.close

"""## Etapa 3 - Acessando a base com fotos de expressões faciais

FER2013 é um conjunto de dados open-source criado por Pierre-Luc Carrier e Aaron Courville, depois cedido publicamente para uma competição Kaggle em 2013. Esse conjunto de dados consiste em 35887 imagens de faces em tons de cinza e 48x48 pixels, com o total de 7 emoções, todas rotuladas.

A partir de um DataFrame obtido de uma base de dados, temos as colunas "emotion" e "pixels". A coluna "emotion" contém um código numérico que varia de 0 a 6. Já a coluna "pixels" contém uma sequência de números que representa os valores em escala de cinza para cada pixel da imagem.

Os rostos foram registrados automaticamente para que a face fique mais ou menos centralizado e ocupe aproximadamente a mesma quantidade de espaço em cada imagem, facilitando o treinamento. A tarefa é categorizar cada rosto com base na emoção mostrada na expressão facial em uma das sete categorias (0 = Raiva, 1 = Nojo, 2 = Medo, 3 = Feliz, 4 = Triste, 5 = Surpresa, 6 = Neutro)
"""

#Obtendo um DataFrame a partir da base de dados fer2013.csv
data = pd.read_csv('fer2013/fer2013.csv')
data.tail()

#Plotando um gráfico (histograma) Imagens x emoções
plt.figure(figsize=(12,6))
plt.hist(data['emotion'], bins=30) #Definindo em 30 divisões
plt.title('Imagens x emoções')

#Classes: = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']

"""## Etapa 4 - Pré-processamento"""

pixels = data['pixels'].tolist()
pixels #Cada linha de um list de pixels (string) representa uma imagem completa

largura, altura = 48, 48
faces = []
amostras = 0 #Variável contadora que indica quantas imagens será obtida através do método cv2_imshow()
for pixel_sequence in pixels:
  face = [int(pixel) for pixel in pixel_sequence.split(' ')]
  face = np.asarray(face).reshape(largura, altura) #Convertendo cada pixel (int) em numpyarray
  faces.append(face)

#Transformando cada sequência de pixels obtida em imagem propriamente dita - Obtendo 10 primeiras imagens
  if(amostras < 10):
    cv2_imshow(face)
  amostras += 1

#Teste
faces #Obtendo um novo array de arrays (matriz de numpyarrays) de pixels que foram convertidos para int durante a iteração do array original "pixels"

print('Número total de imagens no dataframe: ', str(len(faces)))

faces = np.asarray(faces) #Convertendo um array normal (list) em numpyarray para exibir a quantidade e o tamanho através da propriedade shape

faces.shape

#Adicionando mais uma dimensão para trabalhar com imagens em escala de cinza que só possui 1 canal
faces = np.expand_dims(faces, -1) #O -1 indica que será adicionada a dimensão no final do array
faces.shape

#Se fossem imagens coloridas, teríamos 3 canais (seria (35887, 48, 48, 3))

#Normalização - Converter os valores inteiros da matriz de pixels original (da escala de 0 a 255) em valores float (da escala entre 0 e 1)
#Assim, a rede neural poderá processar esses valores mais rapidamente
def normalizar(x):
  x = x.astype('float32')
  x = x / 255.0
  return x

faces = normalizar(faces)

faces[0] #Visualizando os registros obtidos após a normalização - Visualizando o primeiro registro para não gerar muita informação

#Identificando as emoções (classes) utilizando variáveis do tipo dummies (alternativamente poderia utilizar matriz esparsa)
emocoes = pd.get_dummies(data['emotion']).values
emocoes.shape #Obtendo o total de imagens com 7 classes (emoções)

# emocoes[0]

#Convertendo ndarray de volta para array normal
emoction_list = list(emocoes)
imagens = 0

#Imprimindo as possíveis emoções das 10 primeiras imagens
for emoction in emoction_list:
  if imagens < 10:
    print(emoction)
  imagens += 1

#Ao final, indica que uma rede neural terá 7 neurônios na camada de saída, cada uma delas indicando a probabilidade pertencente a cada classe

"""## Etapa 5 - Imports do Tensorflow/Keras

### Importação de camadas das redes neurais:
Camada densa (todos os neurônios de uma camada conectados a todos os neurônios das camadas subsequentes)

Dropout - redução de overfitting(sobreajuste) - quando um modelo se ajusta muito bem ao conjunto de dados anteriormente observado, mas é ineficaz para prever novos dados, devido a desvios causados por erros de medição, o que é comum em conjuntos de dados mais complexos

Activation - Será utilizada a função de ativação numa rede neural

Flatten - Será utilizada a camada flattering, onde é utilizada a matriz de pooling para transformar todos os dados em um array, ou seja, todos os dados serão colunas (vetorização)

Callbacks - funções utilizadas durante o treinamento de uma rede neural


*   ReduceLROnPlateau - Classe responsável pela redução da taxa de aprendizagem caso passe uma certa quantidade seguida de épocas sem melhorar o valor do erro na base de validação, ou seja, sem diminuir esse mesmo valor (e por consequência sem aumentar a acurácia do modelo nessa mesma base), para verificar se nas próximas épocas o modelo consegue melhorar o seu desempenho e continuar com o treinamento.

*   EarlyStopping - Caso a rede neural demore muito para convergir, você pode parar o treinamento para evitar que a rede tente se adaptar ao número maior de épocas.

*   ModelCheckPoint - Irá salvar o melhor modelo no quesito performance em um arquivo.
"""

from sklearn.model_selection import train_test_split #Divisão de dados para treinamento, testes e validação para construção do modelo
from tensorflow.keras.models import Sequential #Definição um modelo sequencial (sequência de camadas de uma rede neural)
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten 
from tensorflow.keras.layers import  Conv2D, MaxPooling2D, BatchNormalization #Definição de uma rede neural convolucional 2D (matriz 2D), max pooling e normalização das camadas de uma rede neural
from tensorflow.keras.losses import categorical_crossentropy #Trabalhando com erros de classificação com mais de 2 classes para medir a eficiência de uma rede neural
from tensorflow.keras.optimizers import Adam # Um dos otimizadores da rede neural para trabalhar com erros de descida de gradiente estocástica
from tensorflow.keras.regularizers import l2 #Outro otimizador para redução de overfitting para melhorar a performance da rede neural
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint 
from tensorflow.keras.models import load_model #Carregamento do modelo treinado
from tensorflow.keras.models import model_from_json #Salvar o modelo no formato JSON

"""## Etapa 6 - Dividir em conjuntos para treinamento e validação"""

#As variáveis de treinamento irão utilizar 90% da base de dados, enquanto as de testes irão utilizar 10% (por isso o parâmetro test_size = 0.1)
X_train, X_test, y_train, y_test = train_test_split(faces, emocoes, test_size = 0.1, random_state = 42)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 41)

print('Número de imagens no conjunto de treinamento:', len(X_train)) 
print('Número de imagens no conjunto de teste:', len(X_test)) 
print('Número de imagens no conjunto de validação:', len(X_val)) 

#Porém, há inconsistência na definição das bases de dados. Durante o treinamento, será corrigida esta inconsistência
#No final de cada época de treinamento de uma rede neural, será realizado um teste utilizando a base de dados de validação

#Salvando a base de testes a ser utlizada posteriormente para geração da matriz de confusão
np.save('mod_xtest', X_test)
np.save('mod_ytest', y_test)

"""## Etapa 7 - Arquitetura do modelo (CNN)

### Arquitetura 1 do modelo

Padding same x valid: https://www.corvil.com/kb/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-tensorflow

Implementação original: https://medium.com/@birdortyedi_23820/deep-learning-lab-episode-3-fer2013-c38f2e052280

Regularizers: https://keras.io/regularizers/

Dropout: http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf
"""

num_features = 64 #Número de filtros da rede neural
num_labels = 7 #Número de classes (neurônios na camada de saída)
batch_size = 64 #Atualizando os pesos de uma rede neural de 64 em 64 registros junto com o valor do erro, a partir do nº de imagens da base de treinamento
epochs = 100 #Serão utilizados 100 épocas
width, height = 48, 48 #Dimensões de uma imagem

#Criando um modelo
model = Sequential()

#Adicionando 2 camadas de convolução (Etapa 1 de uma rede neural convolucional - utilizar a função Relu, que é o parâmetro padrão para trabalhar com redes neurais convolucionais)
model.add(Conv2D(num_features, kernel_size=(3,3), activation='relu', input_shape=(width, height, 1), data_format='channels_last',
                 kernel_regularizer = l2(0.01)))
model.add(Conv2D(num_features, kernel_size=(3,3), activation='relu', padding='same'))

model.add(BatchNormalization()) #Camada de normalização
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid')) #Camada de maxpooling (etapa 2 de uma rede neural convolucional)
model.add(Dropout(0.5)) #Redução de overfitting - Zera os valores de 50% dos neurônios

#Percebe-se que ao final da etapa de pooling, este recurso irá excluir parte da imagem, através do parâmetro padding='valid', considerando apenas as partes importantes da imagem

#---------------------------------------------------------------------------------------------------CRIANDO MAIS CAMADAS DE CONVOLUÇÃO-------------------------------------------------------------------------------------------------------------------
#Criando mais 2 camadas de convolução, porém com o dobro do número de filtros, e 1 camada de maxpooling
model.add(Conv2D(2*num_features, kernel_size=(3,3), activation='relu', padding='same')) 
model.add(BatchNormalization())
model.add(Conv2D(2*num_features, kernel_size=(3,3), activation='relu', padding='same')) 
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid')) 
model.add(Dropout(0.5))

# Criando mais 2 camadas de convolução, porém com o quádruplo do número de filtros, e 1 camada de maxpooling
model.add(Conv2D(2*2*num_features, kernel_size=(3,3), activation='relu', padding='same')) 
model.add(BatchNormalization())
model.add(Conv2D(2*2*num_features, kernel_size=(3,3), activation='relu', padding='same')) 
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid')) 
model.add(Dropout(0.5))

# Criando mais 2 camadas de convolução, porém 8 vezes maior o número de filtros, e 1 camada de maxpooling
model.add(Conv2D(2*2*2*num_features, kernel_size=(3,3), activation='relu', padding='same')) 
model.add(BatchNormalization())
model.add(Conv2D(2*2*2*num_features, kernel_size=(3,3), activation='relu', padding='same')) 
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid')) 
model.add(Dropout(0.5)) #Zerando 50% dos neurônios da camada de maxpooling
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

#Criando uma camada de flattening (etapa 3 de uma rede neural convolucional), ou seja, definindo o número de neurônios na camada de entrada
model.add(Flatten())

#Primeira camada oculta
model.add(Dense(2*2*2*num_features, activation='relu')) #Definindo o número de neurônios nas camadas ocultas, que são densas, ou seja, todos os neurônios de uma camada estão conectados com os neurônios nas camadas subsequentes
model.add(Dropout(0.4)) #Zerando 40% dos neurônios da camada oculta

#Segunda camada oculta
model.add(Dense(2*2*num_features, activation='relu')) 
model.add(Dropout(0.4)) #Zerando 40% dos neurônios da camada oculta

#Terceira camada oculta
model.add(Dense(2*2*num_features, activation='relu')) 
model.add(Dropout(0.5)) #Zerando 50% dos neurônios da camada oculta

# Adicionando uma camada de saída
model.add(Dense(num_labels, activation='softmax'))

model.summary()

#Parâmetros:
#kernel_size: indica o tamanho da matriz de detector de características (feature detector)
#input_shape: indica o tamanho da imagem a ser utilizada no treinamento
#data_format='channels_last': parâmetro padrão que indica que será adicionada mais uma dimensão da imagem no final da matriz
#kernel_regularizer: indica que irá adicionar uma penalidade quando o erro tiver um determinado valor

"""## Etapa 8 - Compilando o modelo
*   Parâmetros Adam:  https://arxiv.org/abs/1412.6980
*   Artigo sobre parâmetros Adam: https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/ 
*   Parâmetros beta: representam a taxa de decaimento exponencial (por exemplo, 0.9) que está relacionado com a taxa de aprendizagem (learning rate - lr)
"""

#Compilando o modelo
model.compile(loss = 'categorical_crossentropy',
              optimizer = Adam(lr = 0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),
                              metrics = ['accuracy'])

arquivo_modelo = 'modelo_01_expressoes.h5'
arquivo_modelo_json = 'modelo_01_expressoes.json'

#Criando uma variável responsável pelo monitoramento do erro na base de validação e da acurácia do modelo de acordo com a execução das funções de callbacks realizadas no final de cada época na fase de treinamento
#patience: nº de épocas
'''O objetivo é verificar se não houve progresso em uma época. Em caso afirmativo, significa que o erro não está diminuindo. Dessa forma, 
a taxa de aprendizagem será alterada multiplicando pelo valor factor, para verificar se nas próximas épocas o val_loss terá melhorias'''

#A cada 3 épocas sem melhorar o erro na base de validação, a taxa de aprendizagem será alterada multiplicando por 0.9
lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3, verbose=1)

#O treinamento será interrompido se o treinamento ocorrer em 8 épocas seguidas sem melhorar o erro
early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=8, verbose=1, mode='auto') 

'''Criando um ponto de verificação (checkpoint) para salvar o modelo com melhores resultados (erros menores) obtidos no treinamento, 
mesmo sobrescrevendo em épocas mais avançadas (por isso o parâmetro save_best_only=True). O objetivo é evitar a perda de informações dos pesos da rede neural
durante o treinamento, pois geralmente leva mais tempo, e durante essa etapa, a rede poderá apresentar algum problema que possa compremeter com os pesos.'''
checkpointer = ModelCheckpoint(arquivo_modelo, monitor='val_loss', verbose=1, save_best_only=True)

"""### Salvando a arquitetura do modelo em um arquivo JSON"""

model_json = model.to_json()
with open(arquivo_modelo_json, 'w') as json_file:
  json_file.write(model_json)

"""## Etapa 9 - Treinando o modelo"""

history = model.fit(np.array(X_train), np.array(y_train),
                    batch_size = batch_size,
                    epochs = epochs,
                    verbose = 1,
                    validation_data = (np.array(X_val), np.array(y_val)),
                    shuffle=True,
                    callbacks=[lr_reducer, early_stopper, checkpointer])

print(history.history)

"""### Gerando gráfico da melhora em cada etapa de treinamento"""

def plota_historico_modelo(historico_modelo):
  fig, axs = plt.subplots(1, 2, figsize=(15, 5))

#Gráfico de acurácia 
  axs[0].plot(range(1, len(historico_modelo.history['accuracy']) + 1), historico_modelo.history['accuracy'], 'r')
  axs[0].plot(range(1, len(historico_modelo.history['val_accuracy']) + 1), historico_modelo.history['val_accuracy'], 'b')
  axs[0].set_title('Acurácia do modelo')
  axs[0].set_ylabel('Acurácia')
  axs[0].set_xlabel('Epoch')
  axs[0].set_xticks(np.arange(1, len(historico_modelo.history['accuracy']) + 1),
                     len(historico_modelo.history['accuracy']) / 10)
  axs[0].legend(['training accuracy', 'validation accuracy'], loc='best')

#Gráfico de erro
  axs[1].plot(range(1, len(historico_modelo.history['loss']) + 1), historico_modelo.history['loss'], 'r')
  axs[1].plot(range(1, len(historico_modelo.history['val_loss']) + 1), historico_modelo.history['val_loss'], 'b')
  axs[1].set_title('Loss do modelo')
  axs[1].set_ylabel('Loss')
  axs[1].set_xlabel('Epoch')
  axs[1].set_xticks(np.arange(1, len(historico_modelo.history['loss']) + 1),
                     len(historico_modelo.history['loss']) / 10)
  axs[1].legend(['training loss', 'validation loss'], loc='best')
  fig.savefig('historico_modelo_mod01.png')  
  
#Visualizando o gráfico parcialmente
plota_historico_modelo(history)

"""### Verificando a acurácia do modelo"""

#Determinando a acurácia do modelo na base de testes
scores = model.evaluate(np.array(X_test), np.array(y_test), batch_size=batch_size)

#Visualizando o erro e a acurácia do modelo na base de testes
scores

print('Acurácia: ' + str(scores[1]))
print('Erro: ' + str(scores[0]))

"""### Carregamento dos dados para gerar a matriz de confusão"""

true_y = [] #Valores reais
pred_y = [] #Valores previstos
x = np.load('mod_xtest.npy')
y = np.load('mod_ytest.npy')

x[0] #Valores dos pixels da primeira imagem

y[0] #Valores das emoções

#Abrindo o arquivo json do modelo (somente leitura)
json_file = open(arquivo_modelo_json, 'r')
loaded_model_json = json_file.read()
json_file.close()

loaded_model = model_from_json(loaded_model_json)
loaded_model.load_weights(arquivo_modelo)

#Efetivamente estamos realizando a previsão das emoções contidas nas imagens
y_pred = loaded_model.predict(x)

y_pred[0] #Carregando as probabilidades de cada emoção. Aquela que tiver a maior probabilidade significa que é a classe correspondente àquela emoção

#Obtendo a lista de probabilidades previstas e probabilidades reais
yp = y_pred.tolist()
yt = y.tolist()
count = 0

len(y) #Obtendo o número de registros da base de testes

for i in range(len(y)):
  yy = max(yp[i]) #Buscando a maior probabilidade prevista
  yyt = max(yt[i]) #Buscando a maior probabilidade real
  pred_y.append(yp[i].index(yy))
  true_y.append(yt[i].index(yyt))

  if(yp[i].index(yy) == yt[i].index(yyt)):
    count += 1

acc = (count / len(y)) * 100

print('Acurácia na base de testes: ' + str(acc))

np.save('truey_mod01', true_y)
np.save('predy_mod01', pred_y)

"""### Gerando a matriz de confusão"""

from sklearn.metrics import confusion_matrix

y_true = np.load('truey_mod01.npy')
y_pred = np.load('predy_mod01.npy')

cm = confusion_matrix(y_true, y_pred)
expressoes = ['Raiva', 'Nojo', 'Medo', 'Feliz', 'Triste', 'Surpreso', 'Neutro']
titulo = 'Matriz de confusão'
print(cm) #Obtendo a matriz de confusão

# Percorrendo a matriz de confusão para obter o total de registros na base de testes
soma = 0
for i in range(len(cm)):
  for j in range(len(cm[i])):
    soma += cm[i][j]
print(soma)

import itertools
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title(titulo)
plt.colorbar()
tick_marks = np.arange(len(expressoes))
plt.xticks(tick_marks, expressoes, rotation=45)
plt.yticks(tick_marks, expressoes);
fmt = 'd' #Formato decimal
thresh = cm.max() / 2

#Adicionando os captions no gráfico da matriz de confusão
for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
  plt.text(j, i, format(cm[i, j], fmt), horizontalalignment='center', color='white' if cm[i,j] > thresh else 'black')

plt.ylabel('Classificação correta')
plt.xlabel('Predição')
plt.savefig('matriz_confusao_mod01.png') #Salvando a matriz de confusão localmente em uma imagem .png

print(cm.max()) #Obtendo o número maior valor da matriz de confusão
print(thresh)

"""### Testando o modelo"""

imagem = cv2.imread('Material/testes/shutterstock_110076917.jpg')
cv2_imshow(imagem)

original = imagem.copy()
gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
cv2_imshow(gray)

face_cascade = cv2.CascadeClassifier('Material/haarcascade_frontalface_default.xml')
faces = face_cascade.detectMultiScale(gray, 1.3, 3)

faces

#Desenhando balding boxes em cada imagem da face
for(x, y, w, h) in faces:
  cv2.rectangle(original, (x, y), (x + w, y + h), (0, 0, 255), 2)
  roi_gray = gray[y:y + h, x:x + w]
  roi_gray = roi_gray.astype('float') / 255.0
  cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)
  prediction = loaded_model.predict(cropped_img)[0]
  cv2.putText(original, expressoes[int(np.argmax(prediction))], (x, y - 10),
              cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 0, 255), 2, cv2.LINE_AA)
cv2_imshow(original)

probabilidades = np.ones((250,300,3), dtype='uint8') * 255

#Mostra o gráfico (barras) apenas se detectou uma face
if len(faces) == 1:
  for(i, (emotion, prob)) in enumerate(zip(expressoes, prediction)):    
    text = '{}: {:.2f}%'.format(emotion, prob * 100) #Nome das emoções x probabilidade
    width = int(prob * 300)
    cv2.rectangle(probabilidades, (7, (i * 35) + 5), (width, (i * 35) + 35), (200, 250, 20), -1)
    cv2.putText(probabilidades, text, (10, (i*35)+23),cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0,0,0), 1, cv2.LINE_AA)

  cv2_imshow(probabilidades)
cv2.imwrite('captura.jpg', original)
cv2.destroyAllWindows()