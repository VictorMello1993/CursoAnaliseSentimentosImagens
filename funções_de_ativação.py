# -*- coding: utf-8 -*-
"""Funções de ativação.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15TfFXUXbh55VLJ8u4LydV4gobjL_N7mC
"""

import numpy as np

#Função degrau
def stepFunction(soma):
  if soma >= 1:
    return 1
  return 0

teste = stepFunction(30)
print(teste)

#Função sigmóide
def sigmoidFunction(soma):
  return 1 / (1 + np.exp(-soma))

teste = sigmoidFunction(-0.358)
print(teste)

#Função tangente hiperbólica
def tangHipFunction(soma):
  return (np.exp(soma) - np.exp(-soma)) / (np.exp(soma) + np.exp(-soma))

teste = tangHipFunction(-0.358)
print(teste)

#Função RELU
def reluFunction(soma):
  if soma >= 0:
    return soma
  return 0
teste = reluFunction(0.358)
print(teste)

#Função linear
def linearFunction(soma):
  return soma
teste = linearFunction(-0.358)
print(teste)

#Softmax
def softMaxFunction(probs):
  ex = np.exp(probs)
  return ex / ex.sum()

valores = [7.0, 2.0, 1.3]
print(softMaxFunction(valores))

"""Mais informações sobre funções de ativação se encontram na documentação do Keras https://keras.io/activations/"""