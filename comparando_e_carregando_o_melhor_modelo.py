# -*- coding: utf-8 -*-
"""Comparando e carregando o melhor modelo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fAG8P4UsLGUItOAHNj22noY5Q8qh6iFt

## Etapa 1 - Importando as bibliotecas
"""

# Commented out IPython magic to ensure Python compatibility.
import cv2
import numpy as np
import pandas as pd
from google.colab.patches import cv2_imshow
import zipfile
# %tensorflow_version 2.x
import tensorflow
tensorflow.__version__

"""## Etapa 2 - Conectando com o Drive e acessando os arquivos"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

#Extraindo todos os arquivos do Material.zip
path = "/content/drive/My Drive/Material.zip"
zip_object = zipfile.ZipFile(file=path, mode="r")
zip_object.extractall("./")

#Extraindo a base fer2013.zip para obter uma base de imagens que serão utilizadas no treinamento do modelo
base_imgs = 'Material/fer2013.zip'
zip_object = zipfile.ZipFile(file=base_imgs, mode='r')
zip_object.extractall('./')
zip_object.close

"""## Comparando modelos"""

from tensorflow.keras.models import load_model
import operator

#Nome dos modelos que serão comparados
arquivos_modelos = ['modelo_01_expressoes.h5', 'modelo_02_expressoes.h5', 'modelo_03_expressoes.h5', 'modelo_04_expressoes.h5', 'modelo_05_expressoes.h5']

modelos = {}

#Carregando a base de testes a ser utilizada para comparação dos modelos
x_test = np.load('Material/mod_xtest.npy')  #Atributos previsores (pixels)
y_test = np.load('Material/mod_ytest.npy') #Atributos classes (emoções)

for modelo in arquivos_modelos:
  model = load_model('Material/' + modelo) #Carregando cada modelo

  #Calcula a acurácia do modelo obtida ao testar na base de teste
  scores = model.evaluate(np.array(x_test), np.array(y_test), batch_size=64)
  print('---'+str(modelo) +'---')
  print('Perda/Loss: ' + str(scores[0]))
  print('Acurácia: ' + str(scores[1]))
  modelos[modelo] = str(scores[1])
  print('\n')

#Ordenando em ordem decrescente os modelos com base no valor da acurácia
modelos_ordenados = sorted(modelos.items(), key=operator.itemgetter(1), reverse=True)
print(modelos_ordenados)

modelos_ordenados[0] #Carregando o melhor modelo

"""## Testes com o modelo carregado"""

imagem = cv2.imread('Material/testes/teste_gabriel.png')
cv2_imshow(imagem)

cascade_faces = 'Material/haarcascade_frontalface_default.xml'
caminho_modelo = 'Material/' + str(modelos_ordenados[0][0])
face_detection = cv2.CascadeClassifier(cascade_faces)
classificador_emocoes = load_model(caminho_modelo, compile=False)
expressoes = ['Raiva', 'Nojo', 'Medo', 'Feliz', 'Triste', 'Surpreso', 'Neutro']

from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array

#Carrega o modelo
face_detection = cv2.CascadeClassifier(cascade_faces)
classificador_emocoes = load_model(caminho_modelo, compile=False)

expressoes = ['Raiva', 'Nojo', 'Medo', 'Feliz', 'Triste', 'Surpreso', 'Neutro']

original = imagem.copy() #Copiando a imagem original
faces = face_detection.detectMultiScale(original,scaleFactor=1.1, minNeighbors=3, minSize=(20,20))
cinza = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY) #Transformando a imagem em escala de cinza

if len(faces) > 0:
  for(fx, fy, fw, fh) in faces:    
    roi = cinza[fy:fy + fh, fx:fx + fw] #Extração do ROI
    roi = cv2.resize(roi, (48,48)) #Redimensionando o tamanho do ROI para melhor precisão na detecção da emoção
    roi = roi.astype('float') / 255.0 #Normalização
    roi = img_to_array(roi) # Converte para array para que a rede possa processar
    roi = np.expand_dims(roi, axis=0) # muda o shape da array
    preds = classificador_emocoes.predict(roi)[0] #Obtendo o array de probabilidades de cada emoção
    print(preds)
    emotion_probability = np.max(preds) #Obtendo a emoção com maior probabilidade
    label = expressoes[preds.argmax()] #Obtendo o label representando a emoção de maior probabilidade
    cv2.putText(original, label, (fx, fy-10), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0,0,255), 2, cv2.LINE_AA)
    cv2.rectangle(original, (fx,fy), (fx+fw, fy+fh), (0,0,255), 2) #Desenhando um retângulo sobre o rosto com o texto em cima com a emoção detectada
else:
  print('Nenhuma face detectada')

cv2_imshow(original)

probabilidades = np.ones((250,300,3), dtype='uint8') * 255

#Mostra o gráfico (barras) apenas se detectou uma face
if len(faces) == 1:
  for(i, (emotion, prob)) in enumerate(zip(expressoes, preds)):
    #Nome das emoções
    text = '{}: {:.2f}%'.format(emotion, prob * 100)
    width = int(prob * 300)
    cv2.rectangle(probabilidades, (7, (i * 35) + 5), (width, (i * 35) + 35), (200, 250, 20), -1)
    cv2.putText(probabilidades, text, (10, (i*35)+23),cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0,0,0), 1, cv2.LINE_AA)

  cv2_imshow(probabilidades)
cv2.imwrite('captura.jpg', original)
cv2.destroyAllWindows()