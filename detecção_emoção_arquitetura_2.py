# -*- coding: utf-8 -*-
"""Detecção Emoção - Arquitetura 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19YsV2n4lrMF05bdkHBz8eGZcrI6mSYsl

# Arquitetura do Modelo 2

## Etapa 1 - Importando as bibliotecas
"""

import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow
import zipfile

cv2.__version__

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow
tensorflow.__version__

"""## Etapa 2 - Conectando com o Drive e acessando os arquivos"""

from google.colab import drive
drive.mount('/content/gdrive')
path = "/content/gdrive/My Drive/Material.zip"
zip_object = zipfile.ZipFile(file=path, mode="r")
zip_object.extractall("./")
base_imgs = 'Material/fer2013.zip'
zip_object = zipfile.ZipFile(file = base_imgs, mode = "r")
zip_object.extractall("./")
zip_object.close()

"""## Etapa 3 - Acessando a base com fotos de expressões faciais"""

data = pd.read_csv('fer2013/fer2013.csv')
data.tail() #Apresentando apenas os últimos registros do arquivo

plt.figure(figsize=(12,6))
plt.hist(data['emotion'], bins=6)
plt.title("Imagens x emoção")
plt.show()

# Classes: ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']

"""## Etapa 4 - Pré-processamento"""

pixels = data['pixels'].tolist()
largura, altura = 48, 48

faces = []
amostras = 0 
for pixel_sequence in pixels:
  face = [int(pixel) for pixel in pixel_sequence.split(' ')]
  face = np.asarray(face).reshape(largura, altura) 
  faces.append(face)
  
  if (amostras < 10):
    cv2_imshow(face)

  amostras = amostras + 1

faces = np.asarray(faces) 
faces = np.expand_dims(faces, -1)

def normalizar(x):
    x = x.astype('float32')
    x = x / 255.0
    return x

faces = normalizar(faces)

emocoes = pd.get_dummies(data['emotion']).values

emocoes.shape

print("Número total de imagens no dataset: "+str(len(faces)))

"""## Etapa 5 - Imports do Tensorflow/Keras

### Importação de camadas das redes neurais:
Camada densa (todos os neurônios de uma camada conectados a todos os neurônios das camadas subsequentes)

Dropout - redução de overfitting(sobreajuste) - quando um modelo se ajusta muito bem ao conjunto de dados anteriormente observado, mas é ineficaz para prever novos dados, devido a desvios causados por erros de medição, o que é comum em conjuntos de dados mais complexos

Activation - Será utilizada a função de ativação numa rede neural

Flatten - Será utilizada a camada flattering, onde é utilizada a matriz de pooling para transformar todos os dados em um array, ou seja, todos os dados serão colunas (vetorização)


Callbacks - funções utilizadas durante o treinamento de uma rede neural


*   ReduceLROnPlateau - Classe responsável pela redução da taxa de aprendizagem caso passe uma certa quantidade seguida de épocas sem melhorar o valor do erro na base de validação, ou seja, sem diminuir esse mesmo valor (e por consequência sem aumentar a acurácia do modelo nessa mesma base), para verificar se nas próximas épocas o modelo consegue melhorar o seu desempenho e continuar com o treinamento.

*   EarlyStopping - Caso a rede neural demore muito para convergir, você pode parar o treinamento para evitar que a rede tente se adaptar ao número maior de épocas.

*   ModelCheckPoint - Irá salvar o melhor modelo no quesito performance em um arquivo.
"""

from sklearn.model_selection import train_test_split #Divisão de dados para treinamento, testes e validação para construção do modelo
from tensorflow.keras.models import Sequential #Definição um modelo sequencial (sequência de camadas de uma rede neural)
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization #Definição de uma rede neural convolucional 2D (matriz 2D), max pooling e normalização das camadas de uma rede neural
from tensorflow.keras.losses import categorical_crossentropy #Trabalhando com erros de classificação com mais de 2 classes para medir a eficiência de uma rede neural
from tensorflow.keras.optimizers import Adam # Um dos otimizadores da rede neural para trabalhar com erros de descida de gradiente estocástica
from tensorflow.keras.regularizers import l2 #Outro otimizador para redução de overfitting para melhorar a performance da rede neural
from tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint #Classes contendo funções de callback de treinamento
from tensorflow.keras.models import load_model #Carregamento do modelo treinado
from tensorflow.keras.models import model_from_json #Salvar o modelo no formato JSON

"""## Etapa 6 - Dividir em conjuntos para treinamento e validação"""

#As variáveis de treinamento irão utilizar 90% da base de dados, enquanto as de testes irão utilizar 10% (por isso o parâmetro test_size = 0.1)
x_train, x_test, y_train, y_test = train_test_split(faces, emocoes, test_size=0.1, random_state=42)
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=41)

print("Número de imagens no conjunto de treinamento:", len(x_train))
print("Número de imagens no conjunto de testes:", len(x_test))
print("Número de imagens no conjunto de validação:", len(y_val))

#No final de cada época de treinamento de uma rede neural, será realizado um teste utilizando a base de dados de validação

#Salvando a base de testes a ser utlizada posteriormente para geração da matriz de confusão
np.save('mod_xtest', x_test)
np.save('mod_ytest', y_test)

"""## Etapa 7 - Arquitetura do Modelo (CNN)

### Arquitetura do modelo

Implementação original: https://github.com/rajeevratan84/DeepLearningCV/blob/master/18.2%20Building%20an%20Emotion%20Detector%20with%20LittleVGG.ipynb
"""

num_features = 32 #Número de filtros da rede neural (Na arquitetura 1 tinha 64 filtros)
num_classes = 7 #Número de classes (neurônios na camada de saída)
width, height = 48, 48
batch_size = 16 #Atualizando os pesos de uma rede neural de 16 em 16 registros junto com o valor do erro, a partir do nº de imagens da base de treinamento (Na arquitetura 1, os pesos eram atualizados de 64 em 64 registros)
epochs = 100

#Criando um modelo
model = Sequential()

#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Adicionando 1 camada de convolução (Etapa 1 de uma rede neural convolucional - utilizar a função elu)
model.add(Conv2D(num_features, (3, 3), padding = 'same', kernel_initializer="he_normal",
                 input_shape = (width, height, 1)))
model.add(Activation('elu'))
model.add(BatchNormalization()) #Camada de normalização

#Adicionando 1 camada de convolução (Etapa 1 de uma rede neural convolucional - utilizar a função elu)
model.add(Conv2D(num_features, (3, 3), padding = "same", kernel_initializer="he_normal", 
                 input_shape = (width, height, 1)))
model.add(Activation('elu'))
model.add(BatchNormalization()) #Camada de normalização

model.add(MaxPooling2D(pool_size=(2, 2))) #Camada de maxpooling (etapa 2 de uma rede neural convolucional)
model.add(Dropout(0.2)) #Redução de overfitting - Zera 20% dos neurônios
#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Adicionando 1 camada de convolução (Etapa 1 de uma rede neural convolucional - utilizar a função elu)
model.add(Conv2D(2*num_features, (3, 3), padding="same", kernel_initializer="he_normal"))
model.add(Activation('elu'))
model.add(BatchNormalization()) #Camada de normalização

#Adicionando 1 camada de convolução (Etapa 1 de uma rede neural convolucional - utilizar a função elu)
model.add(Conv2D(2*num_features, (3, 3), padding="same", kernel_initializer="he_normal"))
model.add(Activation('elu'))
model.add(BatchNormalization()) #Camada de normalização


model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.2)) #Redução de overfitting - Zera 20% dos neurônios
#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Adicionando 1 camada de convolução (Etapa 1 de uma rede neural convolucional - utilizar a função elu)
model.add(Conv2D(2*2*num_features, (3, 3), padding="same", kernel_initializer="he_normal"))
model.add(Activation('elu'))
model.add(BatchNormalization())

#Adicionando 1 camada de convolução (Etapa 1 de uma rede neural convolucional - utilizar a função elu)
model.add(Conv2D(2*2*num_features, (3, 3), padding="same", kernel_initializer="he_normal"))
model.add(Activation('elu'))
model.add(BatchNormalization()) #Camada de normalização

model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.2)) #Redução de overfitting - Zera 20% dos neurônios
#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Adicionando 1 camada de convolução (Etapa 1 de uma rede neural convolucional - utilizar a função elu)
model.add(Conv2D(2*2*2*num_features, (3, 3), padding="same", kernel_initializer="he_normal"))
model.add(Activation('elu'))
model.add(BatchNormalization()) #Camada de normalização

#Adicionando 1 camada de convolução (Etapa 1 de uma rede neural convolucional - utilizar a função elu)
model.add(Conv2D(2*2*2*num_features, (3, 3), padding="same", kernel_initializer="he_normal"))
model.add(Activation('elu'))
model.add(BatchNormalization()) #Camada de normalização

model.add(MaxPooling2D(pool_size=(2, 2))) #Camada de maxpooling
model.add(Dropout(0.2)) #Redução de overfitting - Zera 20% dos neurônios
#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

#Criando uma camada de flattening (etapa 3 de uma rede neural convolucional), ou seja, definindo o número de neurônios na camada de entrada
model.add(Flatten())

#Primeira camada oculta
model.add(Dense(2*num_features, kernel_initializer="he_normal"))
model.add(Activation('elu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))

#Segunda camada oculta
model.add(Dense(2*num_features, kernel_initializer="he_normal"))
model.add(Activation('elu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))

#Camada de saída
model.add(Dense(num_classes, kernel_initializer="he_normal"))
model.add(Activation("softmax"))

print(model.summary())

#Parâmetros:
#kernel_size: indica o tamanho da matriz de detector de características (feature detector)
#input_shape: indica o tamanho da imagem a ser utilizada no treinamento
#data_format='channels_last': parâmetro padrão que indica que será adicionada mais uma dimensão da imagem no final da matriz
#kernel_regularizer: indica que irá adicionar uma penalidade quando o erro tiver um determinado valo

"""## Etapa 8 - Compilando o modelo
*   Parâmetros Adam:  https://arxiv.org/abs/1412.6980
*   Artigo sobre parâmetros Adam: https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/ 
*   Parâmetros beta: representam a taxa de decaimento exponencial (por exemplo, 0.9) que está relacionado com a taxa de aprendizagem (learning rate - lr)
"""

#Compilando o modelo
model.compile(loss=categorical_crossentropy,
              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),
              metrics=['accuracy'])
arquivo_modelo = 'modelo_02_expressoes.h5'
arquivo_modelo_json = 'modelo_02_expressoes.json'
lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3, verbose=1)
early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=8, verbose=1, mode='auto')
checkpointer = ModelCheckpoint(arquivo_modelo, monitor='val_loss', verbose=1, save_best_only=True)

"""### Salvando a arquitetura do modelo em um arquivo JSON"""

model_json = model.to_json()
with open(arquivo_modelo_json, "w") as json_file:
    json_file.write(model_json)

"""## Etapa 9 - Treinando o modelo"""

history = model.fit(np.array(x_train), np.array(y_train),
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(np.array(x_val), np.array(y_val)),
          shuffle=True,
          callbacks=[lr_reducer, early_stopper, checkpointer])

"""* Tempo de treinamento com a arquitetura 2:
  *   Treinamento 1: 4 min em 16 épocas
  *   Treinamento 2: 4 min em 17 épocas
  *   Treinamento 3: 2 min em 9 épocas
  *   Treinamento 4: 2 min em 10 épocas
  *   Treinamento 5: 4 min em 17 épocas
  *   Treinamento 5: 8 min em 19 épocas (recorde: 66% na base de validação e 65% na base de testes)

## Gerando gráfico da melhora em cada etapa do treinamento
"""

def plota_historico_modelo(historico_modelo):
    fig, axs = plt.subplots(1,2,figsize=(15,5))

    #Gráfico de acurácia
    axs[0].plot(range(1,len(historico_modelo.history['accuracy'])+1),
                historico_modelo.history['accuracy'],'r')
    axs[0].plot(range(1,len(historico_modelo.history['val_accuracy'])+1),
                historico_modelo.history['val_accuracy'],'b')
    axs[0].set_title('Acurácia do Modelo')
    axs[0].set_ylabel('Acuracia')
    axs[0].set_xlabel('Epoch')
    axs[0].set_xticks(np.arange(1,len(historico_modelo.history['accuracy'])+1),
                      len(historico_modelo.history['accuracy'])/10)
    axs[0].legend(['training accuracy', 'validation accuracy'], loc='best')

    #Gráfico de erros
    axs[1].plot(range(1,len(historico_modelo.history['loss'])+1),
                historico_modelo.history['loss'],'r')
    axs[1].plot(range(1,len(historico_modelo.history['val_loss'])+1),
                historico_modelo.history['val_loss'],'b')
    axs[1].set_title('Perda/Loss do Modelo')
    axs[1].set_ylabel('Loss')
    axs[1].set_xlabel('Epoch')
    axs[1].set_xticks(np.arange(1,len(historico_modelo.history['loss'])+1),
                      len(historico_modelo.history['loss'])/10)
    axs[1].legend(['training loss', 'validation Loss'], loc='best')
    fig.savefig('historico_modelo_mod02.png') #Salvando os gráficos em um arquivo png
    plt.show()

plota_historico_modelo(history)

"""### Verificando a acurácia do modelo"""

scores = model.evaluate(np.array(x_test), np.array(y_test), batch_size=batch_size)
print("Acurácia: " + str(scores[1]))
print("Perda/Loss: " + str(scores[0]))

"""## Carregaremos os dados para gerar a matriz de confusão"""

true_y=[] #Valores reais
pred_y=[] #Valores previstos
x = np.load('mod_xtest.npy')
y = np.load('mod_ytest.npy')
json_file = open(arquivo_modelo_json, 'r') #Abrindo o arquivo json do modelo (somente leitura)
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json) #Carregando o modelo salvo do arquivo JSON
loaded_model.load_weights(arquivo_modelo) #Carregando os valores dos pesos da rede neural
y_pred= loaded_model.predict(x) #Efetivamente estamos realizando a previsão das emoções contidas nas imagens

#Obtendo a lista de probabilidades previstas e probabilidades reais
yp = y_pred.tolist()
yt = y.tolist()

count = 0
for i in range(len(y)):
    yy = max(yp[i]) #Buscando a maior probabilidade prevista
    yyt = max(yt[i]) #Buscando a maior probabilidade real
    pred_y.append(yp[i].index(yy))
    true_y.append(yt[i].index(yyt))
    if(yp[i].index(yy)== yt[i].index(yyt)):
        count+=1
acc = (count/len(y))*100
np.save('truey__mod01', true_y)
np.save('predy__mod01', pred_y)
print("Acurácia no conjunto de testes: "+str(acc)+"%")

"""## Gerando a Matriz de Confusão"""

from sklearn.metrics import confusion_matrix
y_true = np.load('truey__mod01.npy')
y_pred = np.load('predy__mod01.npy')
cm = confusion_matrix(y_true, y_pred)
expressoes = ["Raiva", "Nojo", "Medo", "Feliz", "Triste", "Surpreso", "Neutro"]
titulo='Matriz de Confusão'
print(cm)

import itertools
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title(titulo)
plt.colorbar()
tick_marks = np.arange(len(expressoes))
plt.xticks(tick_marks, expressoes, rotation=45)
plt.yticks(tick_marks, expressoes)
fmt = 'd' #Formato decimal
thresh = cm.max() / 2.

#Adicionando os captions no gráfico da matriz de confusão
for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    plt.text(j, i, format(cm[i, j], fmt),
            horizontalalignment="center",
            color="white" if cm[i, j] > thresh else "black")

plt.ylabel('Classificação Correta')
plt.xlabel('Predição')
plt.savefig('matriz_confusao_mod02.png') #Salvando a matriz de confusão localmente em uma imagem .png
plt.show()

"""## Testando brevemente o modelo"""

imagem = cv2.imread("Material/testes/20200418_171635.jpg")
cv2_imshow(imagem)

model = load_model("modelo_02_expressoes.h5")
scores = model.evaluate(np.array(x_test), np.array(y_test), batch_size=batch_size)
print("Perda/Loss: " + str(scores[0]))
print("Acurácia: " + str(scores[1]))

expressoes = ["Raiva", "Nojo", "Medo", "Feliz", "Triste", "Surpreso", "Neutro"]
original = imagem.copy()
gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
face_cascade = cv2.CascadeClassifier('Material/haarcascade_frontalface_default.xml')
faces = face_cascade.detectMultiScale(gray, 1.2, 3, minSize = (20, 20))

#Desenhando balding boxes em cada imagem da face
for (x, y, w, h) in faces:
    cv2.rectangle(original, (x, y), (x + w, y + h), (0, 0, 255), 2)
    roi_gray = gray[y:y + h, x:x + w]
    roi_gray = roi_gray.astype("float") / 255.0
    cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)
    cv2.normalize(cropped_img, cropped_img, alpha=0, beta=1, 
                  norm_type=cv2.NORM_L2, dtype=cv2.CV_32F)
    prediction = model.predict(cropped_img)[0]
    cv2.putText(original, expressoes[int(np.argmax(prediction))], (x, y - 10), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.95, (0, 0, 255), 2, cv2.LINE_AA)
cv2_imshow(original)

probabilidades = np.ones((250,300,3), dtype='uint8') * 255

#Mostra o gráfico (barras) apenas se detectou uma face
if len(faces) == 1:
  for(i, (emotion, prob)) in enumerate(zip(expressoes, prediction)):    
    text = '{}: {:.2f}%'.format(emotion, prob * 100) #Nome das emoções x probabilidade
    width = int(prob * 300)
    cv2.rectangle(probabilidades, (7, (i * 35) + 5), (width, (i * 35) + 35), (200, 250, 20), -1)
    cv2.putText(probabilidades, text, (10, (i*35)+23),cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0,0,0), 1, cv2.LINE_AA)

  cv2_imshow(probabilidades)

  #Redimensionando a imagem original e a de probabilidades para as dimensões definidas
  original_resize = cv2.resize(imagem, (300, 400))
  probs_resize = cv2.resize(probabilidades, (300,400))

  combined_img = np.hstack((original_resize, probs_resize)) #Combinando a imagem original com a de probabilidades em uma única imagem  
  cv2.imwrite('captura01.jpg', combined_img)  

cv2.imwrite('captura02.jpg', original)
cv2.destroyAllWindows()

probabilidades.shape